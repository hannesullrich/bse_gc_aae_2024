{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6b2c9b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T17:03:35.656311183Z",
     "start_time": "2023-07-07T17:03:35.427123870Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab95a6d",
   "metadata": {},
   "source": [
    "# Advanced Applied Econometrics\n",
    "\n",
    "# Labor Problem Set 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f712e37c",
   "metadata": {},
   "source": [
    "In order to understand the principle of solving finite horizon models like the one in KW97 via backward induction, this problem set requires you to solve a simple one-person, three-period decision problem.\n",
    "\n",
    "Robinson has to ensure his survival for the next 3 days. He has to work the land in order to produce food. Each day he can choose to work for 8, 12, or 16 hours. He can enjoy the remaining part of the day, such that his leisure time is given by $l_t = 24 - h_t$, where $h_t$ denotes his choice of hours of work.\n",
    "\n",
    "On Day 1 Robinson is completely unskilled and no matter how many hours he works, he gets 1 unit of produce. Working more  than 8 hours a day allows Robinson to learn how to take better care of the crops, such that he is able to produce more. In particular, for every additional 4 hours of work on either day Robinson levels up his farming skills by 1 unit. E.g., if Robinson works for 16 hours on Day 1, his skills/experience on Day 2 will be 2; if Robinson then also works 12 hours on Day 2, his skills/experience on Day 3 would be 3.  Produce $c_t$ is a function of experience $e_t$:\n",
    "\n",
    "\\begin{equation}\n",
    "c_t = {(1+ 0.25e_t)}^2\n",
    "\\tag{1}\n",
    "\\end{equation}\n",
    "\n",
    "Robinson gains utility from consumption and leisure:\n",
    "\n",
    "\\begin{equation}\n",
    "u(c_t; l_t) = {c_t}^\\alpha {l_t}^\\beta\n",
    "\\tag{2}\n",
    "\\end{equation}\n",
    "\n",
    "with $ \\alpha = \\beta  = 0.5 $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9d3809",
   "metadata": {},
   "source": [
    "## Questions A:\n",
    "\n",
    "1. If Robinson had to survive only for 1 day, how many hours would he work?\n",
    "How much utility would he get? What incentive does Robinson have to make a different choice on Day 1 if he has to survive for 3 days?\n",
    "\n",
    "2. Is Robinson risk averse?\n",
    "\n",
    "3. Are consumption and leisure substitutes for Robinson?\n",
    "\n",
    "4. What are the state variables of the model? How many states are there? Write down a state space representation as a matrix with dimensions *number of states* by *number of state variables*.\n",
    "\n",
    "5. In dynamic programming problems like this one, the agent makes choices based on the choice specific value functions. These are given by the flow utility plus the continuation value. Assume that continuation values on the last day are zero. What would be optimal number of hours of work for Robinson on Day 3?\n",
    "\n",
    "6. Note that the flow utilities you calculated in order to arrive to the previous answer are the Day 2 continuation values. What would be optimal numbers of hours to work for Robinson on Day 2? And Day 1?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95360db3",
   "metadata": {},
   "source": [
    "### See slides for solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0542135",
   "metadata": {},
   "source": [
    "## Question B:\n",
    "\n",
    "Solve and simulate the model:\n",
    "\n",
    "- you have found the solution of the model when you have calculated the choice specific value functions at each state\n",
    "- your simulation output should be a matrix or a matrix-like object with columns \"Day\", \"Choice\", and \"Choice Specific Value Function\"\n",
    "- *(bonus) your program is general and scalable if you can use the exact same code in order to solve Robinson's survival problem for 30 days (instead of 3)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6e9c076",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T17:03:35.669167957Z",
     "start_time": "2023-07-07T17:03:35.667593763Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_state_space(options):\n",
    "    \"\"\"Creates state space for the Robinson Crusoe problem.\n",
    "\n",
    "    Args:\n",
    "        options (dict): A dictionary with key parameters for the construction of the model.\n",
    "\n",
    "    Returns:\n",
    "        states (np.array): A 2d array of shape (num_states, num_state_variables)\n",
    "         with all possible states.\n",
    "        indexer (np.array): A 2d array of shape (num_periods, max_possible_exp)\n",
    "            with the index of each state in the states array.\n",
    "    \"\"\"\n",
    "    num_periods = options[\"num_periods\"]\n",
    "    max_possible_exp = num_periods * 2 + 1\n",
    "    indexer = np.full(shape=(num_periods, max_possible_exp), fill_value=-99, dtype=int)\n",
    "    states = []\n",
    "    state_ind = 0\n",
    "    for period in range(num_periods):\n",
    "        possible_exp_levels = range(period * 2 + 1)\n",
    "        for exp_level in possible_exp_levels:\n",
    "            states += [[period, exp_level]]\n",
    "            indexer[period, exp_level] = state_ind\n",
    "            state_ind += 1\n",
    "    return np.array(states), indexer\n",
    "\n",
    "\n",
    "def utility_function(hour_choice, exp_level, params):\n",
    "    \"\"\"Calculates the flow utility of a given choice dependent on the experience level.\n",
    "\n",
    "    Args:\n",
    "        hour_choice (int): The number of hours worked.\n",
    "        exp_level (int): The experience level.\n",
    "        params (dict): A dictionary with the parameterization for the model.\n",
    "\n",
    "    Returns:\n",
    "        utility (float): The flow utility of the choice.\n",
    "    \"\"\"\n",
    "    consumption = (1 + 0.25 * exp_level) ** 2\n",
    "    utility_consumption = consumption ** params[\"alpha\"]\n",
    "    utility_leisure = (24 - hour_choice) ** params[\"alpha\"]\n",
    "    utility = utility_consumption * utility_leisure\n",
    "    return utility\n",
    "\n",
    "\n",
    "def state_next_period(state, hour_choice):\n",
    "    \"\"\"Calculates the state in the next period given the current state and the choice.\n",
    "\n",
    "    Args:\n",
    "        state (list): A list with the current period and experience level.\n",
    "        hour_choice (int): The number of hours worked.\n",
    "\n",
    "    Returns:\n",
    "        state_next (np.array): A 1d array with the state (period and experience level)\n",
    "         in the next period.\n",
    "    \"\"\"\n",
    "    period, exp_level = state\n",
    "    if hour_choice == 8:\n",
    "        exp_level_next = exp_level\n",
    "    elif hour_choice == 12:\n",
    "        exp_level_next = exp_level + 1\n",
    "    elif hour_choice == 16:\n",
    "        exp_level_next = exp_level + 2\n",
    "    else:\n",
    "        raise ValueError(\"Invalid choice\")\n",
    "    return np.array([period + 1, exp_level_next])\n",
    "\n",
    "\n",
    "def backwards_induction(states, indexer, options, params):\n",
    "    \"\"\"Calculates the choice specific values for each state in the state space.\n",
    "\n",
    "    Args:\n",
    "        states (np.array): A 2d array of shape (num_states, num_state_variables)\n",
    "         with all possible states.\n",
    "        indexer (np.array): A 2d array of shape (num_periods, max_possible_exp)\n",
    "            with the index of each state in the states array.\n",
    "        options (dict): A dictionary with key parameters for the construction of the model.\n",
    "        params (dict): A dictionary with the parameterization for the model.\n",
    "\n",
    "    Returns:\n",
    "        choice_specific_values (np.array): A 2d array of shape (num_states, num_choices)\n",
    "            with the choice specific values for each state.\n",
    "    \"\"\"\n",
    "    num_periods = options[\"num_periods\"]\n",
    "    num_choices = len(options[\"choices\"])\n",
    "    num_states = states.shape[0]\n",
    "    choice_specific_values = np.zeros((num_states, num_choices), dtype=float)\n",
    "    for period in range(num_periods - 1, -1, -1):\n",
    "        states_period = states[states[:, 0] == period]\n",
    "        for state in states_period:\n",
    "            current_state_index = indexer[state[0], state[1]]\n",
    "            for choice in range(num_choices):\n",
    "                hours_worked = options[\"choices\"][choice]\n",
    "                exp_level = state[1]\n",
    "                utility = utility_function(hours_worked, exp_level, params)\n",
    "                if period == num_periods - 1:\n",
    "                    continuation_value = 0\n",
    "                else:\n",
    "                    state_next = state_next_period(state, hours_worked)\n",
    "                    state_next_index = indexer[state_next[0], state_next[1]]\n",
    "                    # Get the maximum continuation value of next period\n",
    "                    continuation_value = choice_specific_values[\n",
    "                        state_next_index, :\n",
    "                    ].max()\n",
    "\n",
    "                choice_specific_values[current_state_index, choice] = (\n",
    "                    utility + continuation_value\n",
    "                )\n",
    "    return choice_specific_values\n",
    "\n",
    "\n",
    "def solve_model(options, params):\n",
    "    \"\"\"Solves the model and returns the state space, indexer and choice specific values.\n",
    "\n",
    "    Args:\n",
    "        options (dict): A dictionary with key parameters for the construction of the model.\n",
    "        params (dict): A dictionary with the parameterization for the model.\n",
    "\n",
    "    Returns:\n",
    "        states (np.array): A 2d array of shape (num_states, num_state_variables)\n",
    "         with all possible states.\n",
    "        indexer (np.array): A 2d array of shape (num_periods, max_possible_exp)\n",
    "            with the index of each state in the states array.\n",
    "        choice_specific_values (np.array): A 2d array of shape (num_states, num_choices)\n",
    "            with the choice specific values for each state.\n",
    "    \"\"\"\n",
    "    states, indexer = create_state_space(options)\n",
    "    choice_specific_values = backwards_induction(states, indexer, options, params)\n",
    "    return states, indexer, choice_specific_values\n",
    "\n",
    "\n",
    "def simulate_model(options, params):\n",
    "    \"\"\"Simulates the model and returns a dataframe with the optimal choices, value functions\n",
    "        and the level of experience at each day.\n",
    "\n",
    "    Args:\n",
    "        options (dict): A dictionary with key parameters for the construction of the model.\n",
    "        params (dict): A dictionary with the parameterization for the model.\n",
    "\n",
    "    Returns:\n",
    "        df (pd.DataFrame): Dataframe with the simulated data.\n",
    "    \"\"\"\n",
    "    states, indexer, choice_specific_values = solve_model(options, params)\n",
    "\n",
    "    num_periods = options[\"num_periods\"]\n",
    "\n",
    "    # Generate empty dataframe with a row for each day\n",
    "    index = pd.Index(range(num_periods), name=\"day\")\n",
    "    df = pd.DataFrame(index=index, columns=[\"choice\", \"value_function\", \"exp_level\"])\n",
    "    # There is only one initial state\n",
    "    current_state = [0, 0]\n",
    "    for period in range(num_periods):\n",
    "        current_state_index = indexer[current_state[0], current_state[1]]\n",
    "        choice = choice_specific_values[current_state_index, :].argmax()\n",
    "        value_function = choice_specific_values[current_state_index, choice]\n",
    "        hour_choice = options[\"choices\"][choice]\n",
    "        # Save optimal data in DataFrame\n",
    "        df.loc[period, \"choice\"] = hour_choice\n",
    "        df.loc[period, \"value_function\"] = value_function\n",
    "        df.loc[period, \"exp_level\"] = current_state[1]\n",
    "\n",
    "        current_state = state_next_period(current_state, hour_choice)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5568096b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T17:03:35.711029402Z",
     "start_time": "2023-07-07T17:03:35.671119305Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>choice</th>\n",
       "      <th>value_function</th>\n",
       "      <th>exp_level</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>15.071068</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>12.242641</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    choice value_function exp_level\n",
       "day                                \n",
       "0       16      15.071068         0\n",
       "1       16      12.242641         2\n",
       "2        8            8.0         4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "options_robinson = {\n",
    "    \"num_periods\": 3,\n",
    "    \"choices\": [8, 12, 16],\n",
    "}\n",
    "\n",
    "params_robinson = {\"alpha\": 0.5}\n",
    "\n",
    "simulate_model(options_robinson, params_robinson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9557ead",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T17:03:35.711329859Z",
     "start_time": "2023-07-07T17:03:35.690427878Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
